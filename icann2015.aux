\relax 
\citation{wysoski2008fast}
\citation{canny1986computational}
\citation{toygar2004multiple}
\citation{wei2006robust}
\citation{lowe2004distinctive}
\citation{bay2008speeded}
\citation{riesenhuber1999hierarchical}
\citation{lenero20113}
\citation{furber2014spinnaker}
\citation{hopfield1995pattern}
\citation{natschlager1998spatial}
\citation{maass1997networks}
\citation{gupta2007character}
\citation{6467270}
\citation{camunas2012event}
\citation{delorme2001networks}
\citation{eliasmith2011nengo}
\citation{eliasmith2012large}
\citation{naylor2013managing}
\citation{o2013real}
\citation{delbruck2008frame}
\citation{6252490}
\citation{galluppi2012real}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{lazzaro1995multi}
\citation{wei2006robust}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:SysOverViewa}{{1a}{2}}
\newlabel{sub@fig:SysOverViewa}{{a}{2}}
\newlabel{fig:SysOverViewb}{{1b}{2}}
\newlabel{sub@fig:SysOverViewb}{{b}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces System overview of the dynamipc hand posture recognition platform. The silicon retina connects to the SpiNNaker system through an FPGA board. Spikes from the retina are streamed to the SpiNNaker system through this Spartan-6 FPGA board. The jAER software configures the retina and displays its outgoing spikes through the USB connection. The host sets up the runtime parameters off-line and downloads the network model to the SpiNNaker system. \relax }}{2}}
\newlabel{fig:SysOverView}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {II}The Neuromorphic Platform}{2}}
\newlabel{sec:np}{{II}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Silicon Retina}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces System diagram. Each element represents one SpiNNaker chip with the local memory. Every chip connects to the other through the six bi-directional on-board links. \relax }}{2}}
\newlabel{fig:sysdia}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}SpiNNaker System}{2}}
\citation{appnote8}
\citation{galluppi2012real}
\citation{5537164}
\citation{6706931}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces 103 Machine PCB\relax }}{3}}
\newlabel{fig:48node}{{3}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-C}}Interfacing AER Sensors}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Convolutional Neural Networks}{3}}
\newlabel{sec:cnn}{{III}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Each individual neuron in the convolution layer (right matrix) connects to its receptive field using the same kernel. The value of the kernel can be seen as the synaptic weights between the connected neurons.\relax }}{3}}
\newlabel{fig:conv}{{4}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Model 1. The retina input convolves with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The templates are considered as convolution kernels in the last layer. The winner-take-all (WTA) circuit can be used as an option to show the template matching result more clearly. \relax }}{3}}
\newlabel{fig:model1}{{5}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Model Description}{3}}
\newlabel{sec:mds}{{\unhbox \voidb@x \hbox {III-A}}{3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-A}1}Model 1. Template Matching}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Templates of the five postures: `Fist',`Index Finger', `Victory Sign', `Full Hand' and `Thumb up'.\relax }}{3}}
\newlabel{fig:template}{{6}{3}}
\citation{lecun1998gradient}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Real parts of the Gabor filters orienting four directions.\relax }}{4}}
\newlabel{fig:gabor}{{7}{4}}
\newlabel{equ:gabor}{{1}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {III-A}2}Model 2. Trained MLP}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Experiments Set-up}{4}}
\newlabel{sec:tat}{{\unhbox \voidb@x \hbox {III-B}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Model 2. The retina input convolves with Gabor filters in the second layer, and then shrinks the sizes in the pooling layer. The following tracking layer finds the most active area of some fixed size, moves the posture to the centre and pushes the image to the trained MLP. The winner-take-all (WTA) layer can be used as an option to show the template matching result more clearly.\relax }}{4}}
\newlabel{fig:model2}{{8}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Sizes of the convolutional neural networks.\relax }}{4}}
\newlabel{tbl:m1}{{Ia}{4}}
\newlabel{sub@tbl:m1}{{a}{4}}
\newlabel{tbl:m2}{{Ib}{4}}
\newlabel{sub@tbl:m2}{{b}{4}}
\newlabel{tbl:nns}{{I}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Experiment Results}{4}}
\newlabel{sec:exp}{{\unhbox \voidb@x \hbox {III-C}}{4}}
\citation{la2008response}
\citation{burkitt2006review}
\citation{siegert1951first}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Neural responses with time of four experiments to the same recorded moving postures. The recognition output is normalised to \unhbox \voidb@x \hbox {[-1, 1]}. Every point represents the highest response in a specific population (different colour) for a 30\nobreakspace  {}ms frame. The 1st plot refers to Model 1 with the full input resolution, and the 2nd plot Model 1 with the sub-sampled input resolution; and the 3rd and fourth plots both refer to Model 2, and with high and low input resolution respectively. \relax }}{5}}
\newlabel{fig:matlabrec}{{9}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Real-Time Recognition on SpiNNaker}{5}}
\newlabel{sec:rrs}{{IV}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Moving from Rate-based Artificial Neurons to Spiking Neurons}{5}}
\newlabel{equ:lif}{{2}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Recognition results in \%\relax }}{5}}
\newlabel{tbl:rsl}{{II}{5}}
\newlabel{equ:consI}{{3}{5}}
\newlabel{equ:sde}{{4}{5}}
\newlabel{equ:ou}{{5}{5}}
\newlabel{equ:sgt}{{6}{5}}
\citation{video1}
\citation{video2}
\citation{video3}
\citation{video1}
\citation{video1}
\citation{video2}
\citation{video2}
\citation{video3}
\citation{video3}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Live Recognition}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Recognition of Recorded Data}{6}}
\newlabel{fig:live1}{{10a}{6}}
\newlabel{sub@fig:live1}{{a}{6}}
\newlabel{fig:live2}{{10b}{6}}
\newlabel{sub@fig:live2}{{b}{6}}
\newlabel{fig:live3}{{10c}{6}}
\newlabel{sub@fig:live3}{{c}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Snapshots of the real-time dynamic posture recognition system on SpiNNaker. \relax }}{6}}
\newlabel{fig:live}{{10}{6}}
\citation{elmezain2009hidden}
\bibdata{refs}
\bibcite{wysoski2008fast}{1}
\bibcite{canny1986computational}{2}
\bibcite{toygar2004multiple}{3}
\bibcite{wei2006robust}{4}
\bibcite{lowe2004distinctive}{5}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Real-time neural responses of two experiments on SpiNNaker with time to the same recorded postures. These two experiments only differ on the input resolution. The result of the high input resolution test is plotted the first with a sample frame of 30\nobreakspace  {}ms; while the 3rd plot shows the same result with a sample frame of 300\nobreakspace  {}ms. The latter two plots refer to the smaller input resolution. Every point represents the over all number of spikes of a specific population (different colour) in a `frame'. \relax }}{7}}
\newlabel{fig:spikerec}{{11}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Real-time recognition results on SpiNNaker in \%\relax }}{7}}
\newlabel{tbl:srr}{{III}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion and Future Work}{7}}
\newlabel{sec:cfw}{{V}{7}}
\newlabel{fig:ssa}{{12a}{7}}
\newlabel{sub@fig:ssa}{{a}{7}}
\newlabel{fig:rec0}{{12b}{7}}
\newlabel{sub@fig:rec0}{{b}{7}}
\newlabel{fig:rec1}{{12c}{7}}
\newlabel{sub@fig:rec1}{{c}{7}}
\newlabel{fig:rec5}{{12e}{7}}
\newlabel{sub@fig:rec5}{{e}{7}}
\newlabel{fig:rect}{{12f}{7}}
\newlabel{sub@fig:rect}{{f}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Spikes captured during the live recognition of the recorded retinal input with the resolution of 128$\times $128. \relax }}{7}}
\newlabel{fig:rps}{{12}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Acknowledgement}{7}}
\newlabel{sec:ack}{{VI}{7}}
\@writefile{toc}{\contentsline {section}{References}{7}}
\bibcite{bay2008speeded}{6}
\bibcite{riesenhuber1999hierarchical}{7}
\bibcite{lenero20113}{8}
\bibcite{furber2014spinnaker}{9}
\bibcite{hopfield1995pattern}{10}
\bibcite{natschlager1998spatial}{11}
\bibcite{maass1997networks}{12}
\bibcite{gupta2007character}{13}
\bibcite{6467270}{14}
\bibcite{camunas2012event}{15}
\bibcite{delorme2001networks}{16}
\bibcite{eliasmith2011nengo}{17}
\bibcite{eliasmith2012large}{18}
\bibcite{naylor2013managing}{19}
\bibcite{o2013real}{20}
\bibcite{delbruck2008frame}{21}
\bibcite{6252490}{22}
\bibcite{galluppi2012real}{23}
\bibcite{lazzaro1995multi}{24}
\bibcite{appnote8}{25}
\bibcite{5537164}{26}
\bibcite{6706931}{27}
\bibcite{lecun1998gradient}{28}
\bibcite{la2008response}{29}
\bibcite{burkitt2006review}{30}
\bibcite{siegert1951first}{31}
\bibcite{video1}{32}
\bibcite{video2}{33}
\bibcite{video3}{34}
\bibcite{elmezain2009hidden}{35}
\bibstyle{ieeetr}
\newlabel{fig:ssa32}{{13a}{8}}
\newlabel{sub@fig:ssa32}{{a}{8}}
\newlabel{fig:rec032}{{13b}{8}}
\newlabel{sub@fig:rec032}{{b}{8}}
\newlabel{fig:rec132}{{13c}{8}}
\newlabel{sub@fig:rec132}{{c}{8}}
\newlabel{fig:rec532}{{13e}{8}}
\newlabel{sub@fig:rec532}{{e}{8}}
\newlabel{fig:rect32}{{13f}{8}}
\newlabel{sub@fig:rect32}{{f}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Spikes captured during the live recognition of the recorded retinal input with the resolution of 32$\times $32. \relax }}{8}}
\newlabel{fig:rps32}{{13}{8}}
\@writefile{toc}{\contentsline {section}{Biographies}{9}}
\@writefile{toc}{\contentsline {subsection}{Qian Liu}{9}}
\@writefile{toc}{\contentsline {subsection}{Steve Furber}{9}}
